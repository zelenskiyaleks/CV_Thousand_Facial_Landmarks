При построении оптимального кода основное внимание приделил выбору оптимизатора(думаю что опробовал все возможные оптимизаторы, лучшим оказался AdamW), подбору размера бача(пробовал различные размеры, лучшим оказался 128), подбору размера тренировочных данных и валидационных(лучшим оказался 0.9 тренировочные и 0.1 валидационные)).
Так-же большой прирост дал выбор глубокой нейронной сети(выбрал resnet152) и обучение на всех тренировочных данных.

При изучении картинок заметил что необычные картинки были в тестовых данных,а не в тренировочных. Если бы было наоборот - я бы удалил такие картинки из тренировочных данных, но для текущей ситуации ничего не смог придумать чтоб улучшить модель. 